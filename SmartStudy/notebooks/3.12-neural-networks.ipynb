{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network MLP\n",
    "\n",
    "This notebook will focus on the implementation of an MLP to predict student GPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Gender  StudyTimeWeekly  Absences  Extracurricular  Sports  Music  \\\n",
      "0   17       1        19.833723         7                0       0      1   \n",
      "1   18       0        15.408756         0                0       0      0   \n",
      "2   15       0         4.210570        26                0       0      0   \n",
      "3   17       1        10.028829        14                1       0      0   \n",
      "4   17       1         4.672495        17                0       0      0   \n",
      "\n",
      "   Volunteering       GPA  ParentalInfluence  TutoringEffect  \n",
      "0             0  2.929196                  4       19.833723  \n",
      "1             0  3.042915                  1        0.000000  \n",
      "2             0  0.112602                  6        0.000000  \n",
      "3             0  2.054218                  9        0.000000  \n",
      "4             0  1.288061                  6        4.672495  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "print(df.head())\n",
    "\n",
    "# Data Splitting & Normalization\n",
    "scaler = StandardScaler()\n",
    "input = df.drop(columns=['GPA'], errors='ignore')\n",
    "input = scaler.fit_transform(input)\n",
    "labels = df['GPA']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(input, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eblac\\anaconda3\\envs\\smartstudy_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.4024 - mean_absolute_error: 1.2979 - val_loss: 0.4061 - val_mean_absolute_error: 0.5123\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3074 - mean_absolute_error: 0.4418 - val_loss: 0.1718 - val_mean_absolute_error: 0.3351\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1383 - mean_absolute_error: 0.2941 - val_loss: 0.1477 - val_mean_absolute_error: 0.3085\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1160 - mean_absolute_error: 0.2732 - val_loss: 0.1330 - val_mean_absolute_error: 0.2917\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1039 - mean_absolute_error: 0.2559 - val_loss: 0.1188 - val_mean_absolute_error: 0.2749\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0950 - mean_absolute_error: 0.2429 - val_loss: 0.1099 - val_mean_absolute_error: 0.2635\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0876 - mean_absolute_error: 0.2323 - val_loss: 0.0996 - val_mean_absolute_error: 0.2493\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0724 - mean_absolute_error: 0.2100 - val_loss: 0.0930 - val_mean_absolute_error: 0.2412\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0701 - mean_absolute_error: 0.2123 - val_loss: 0.0882 - val_mean_absolute_error: 0.2331\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0659 - mean_absolute_error: 0.2042 - val_loss: 0.0828 - val_mean_absolute_error: 0.2267\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0615 - mean_absolute_error: 0.1970 - val_loss: 0.0826 - val_mean_absolute_error: 0.2241\n",
      "Epoch 12/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0626 - mean_absolute_error: 0.2004 - val_loss: 0.0794 - val_mean_absolute_error: 0.2206\n",
      "Epoch 13/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0587 - mean_absolute_error: 0.1940 - val_loss: 0.0767 - val_mean_absolute_error: 0.2173\n",
      "Epoch 14/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0577 - mean_absolute_error: 0.1913 - val_loss: 0.0757 - val_mean_absolute_error: 0.2171\n",
      "Epoch 15/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0567 - mean_absolute_error: 0.1889 - val_loss: 0.0766 - val_mean_absolute_error: 0.2165\n",
      "Epoch 16/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0553 - mean_absolute_error: 0.1879 - val_loss: 0.0730 - val_mean_absolute_error: 0.2119\n",
      "Epoch 17/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0542 - mean_absolute_error: 0.1854 - val_loss: 0.0737 - val_mean_absolute_error: 0.2146\n",
      "Epoch 18/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0531 - mean_absolute_error: 0.1838 - val_loss: 0.0750 - val_mean_absolute_error: 0.2183\n",
      "Epoch 19/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0539 - mean_absolute_error: 0.1848 - val_loss: 0.0738 - val_mean_absolute_error: 0.2135\n",
      "Epoch 20/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0505 - mean_absolute_error: 0.1776 - val_loss: 0.0736 - val_mean_absolute_error: 0.2130\n",
      "Epoch 21/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0475 - mean_absolute_error: 0.1743 - val_loss: 0.0731 - val_mean_absolute_error: 0.2128\n",
      "Epoch 22/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0508 - mean_absolute_error: 0.1791 - val_loss: 0.0749 - val_mean_absolute_error: 0.2161\n",
      "Epoch 23/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0501 - mean_absolute_error: 0.1748 - val_loss: 0.0739 - val_mean_absolute_error: 0.2152\n",
      "Epoch 24/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0522 - mean_absolute_error: 0.1819 - val_loss: 0.0742 - val_mean_absolute_error: 0.2180\n",
      "Epoch 25/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0472 - mean_absolute_error: 0.1726 - val_loss: 0.0725 - val_mean_absolute_error: 0.2134\n",
      "Epoch 26/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0488 - mean_absolute_error: 0.1758 - val_loss: 0.0732 - val_mean_absolute_error: 0.2141\n",
      "Epoch 27/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0466 - mean_absolute_error: 0.1720 - val_loss: 0.0747 - val_mean_absolute_error: 0.2139\n",
      "Epoch 28/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0491 - mean_absolute_error: 0.1748 - val_loss: 0.0733 - val_mean_absolute_error: 0.2146\n",
      "Epoch 29/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0445 - mean_absolute_error: 0.1668 - val_loss: 0.0733 - val_mean_absolute_error: 0.2123\n",
      "Epoch 30/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0453 - mean_absolute_error: 0.1711 - val_loss: 0.0731 - val_mean_absolute_error: 0.2117\n",
      "Epoch 31/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0459 - mean_absolute_error: 0.1717 - val_loss: 0.0724 - val_mean_absolute_error: 0.2129\n",
      "Epoch 32/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0432 - mean_absolute_error: 0.1651 - val_loss: 0.0714 - val_mean_absolute_error: 0.2107\n",
      "Epoch 33/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0444 - mean_absolute_error: 0.1650 - val_loss: 0.0723 - val_mean_absolute_error: 0.2117\n",
      "Epoch 34/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0439 - mean_absolute_error: 0.1650 - val_loss: 0.0756 - val_mean_absolute_error: 0.2164\n",
      "Epoch 35/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0445 - mean_absolute_error: 0.1668 - val_loss: 0.0736 - val_mean_absolute_error: 0.2155\n",
      "Epoch 36/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0415 - mean_absolute_error: 0.1618 - val_loss: 0.0716 - val_mean_absolute_error: 0.2121\n",
      "Epoch 37/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0386 - mean_absolute_error: 0.1564 - val_loss: 0.0755 - val_mean_absolute_error: 0.2164\n",
      "Epoch 38/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0413 - mean_absolute_error: 0.1630 - val_loss: 0.0740 - val_mean_absolute_error: 0.2168\n",
      "Epoch 39/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0413 - mean_absolute_error: 0.1631 - val_loss: 0.0734 - val_mean_absolute_error: 0.2148\n",
      "Epoch 40/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0440 - mean_absolute_error: 0.1658 - val_loss: 0.0725 - val_mean_absolute_error: 0.2133\n",
      "Epoch 41/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0413 - mean_absolute_error: 0.1614 - val_loss: 0.0755 - val_mean_absolute_error: 0.2155\n",
      "Epoch 42/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0426 - mean_absolute_error: 0.1628 - val_loss: 0.0725 - val_mean_absolute_error: 0.2114\n",
      "Epoch 43/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0391 - mean_absolute_error: 0.1585 - val_loss: 0.0726 - val_mean_absolute_error: 0.2121\n",
      "Epoch 44/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0398 - mean_absolute_error: 0.1578 - val_loss: 0.0753 - val_mean_absolute_error: 0.2152\n",
      "Epoch 45/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0370 - mean_absolute_error: 0.1536 - val_loss: 0.0738 - val_mean_absolute_error: 0.2123\n",
      "Epoch 46/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0402 - mean_absolute_error: 0.1589 - val_loss: 0.0744 - val_mean_absolute_error: 0.2151\n",
      "Epoch 47/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0419 - mean_absolute_error: 0.1653 - val_loss: 0.0734 - val_mean_absolute_error: 0.2126\n",
      "Epoch 48/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0384 - mean_absolute_error: 0.1564 - val_loss: 0.0739 - val_mean_absolute_error: 0.2152\n",
      "Epoch 49/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0374 - mean_absolute_error: 0.1545 - val_loss: 0.0765 - val_mean_absolute_error: 0.2179\n",
      "Epoch 50/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0371 - mean_absolute_error: 0.1519 - val_loss: 0.0757 - val_mean_absolute_error: 0.2175\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Mean Squared Error: 0.06505470337176066\n",
      "Mean Absolute Error: 0.2090011975655669\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define the MLP model\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "mlp_model.add(Dense(32, activation='relu'))\n",
    "mlp_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp_model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Predict using the model\n",
    "Y1_pred = mlp_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y_test, Y1_pred)\n",
    "mae = mean_absolute_error(Y_test, Y1_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabPFN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eblac\\anaconda3\\envs\\smartstudy_env\\Lib\\site-packages\\tabpfn\\base.py:100: UserWarning: Downloading model to C:\\Users\\eblac\\AppData\\Roaming\\tabpfn\\tabpfn-v2-regressor.ckpt.\n",
      "  model, bardist, config_ = load_model_criterion_config(\n",
      "c:\\Users\\eblac\\anaconda3\\envs\\smartstudy_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.05441965792133698\n",
      "Mean Absolute Error: 0.18885700044434858\n"
     ]
    }
   ],
   "source": [
    "# TabPFN\n",
    "from tabpfn import TabPFNRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Train and predict TabPFN\n",
    "reg = TabPFNRegressor(random_state=42)\n",
    "reg.fit(X_train, Y_train)\n",
    "Y3_pred = reg.predict(X_test)\n",
    "\n",
    "# evaluation\n",
    "print('Mean Squared Error:', mean_squared_error(Y_test, Y3_pred))\n",
    "print('Mean Absolute Error:', mean_absolute_error(Y_test, Y3_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (Cross-validation, etc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartstudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
